{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6329be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a5dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\HP\\\\Downloads\\\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48170022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'TotalCharges' to numeric and fill missing values with 0\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n",
    "df['TotalCharges'].fillna(0, inplace=True)\n",
    "\n",
    "# Map 'Churn' column to binary values\n",
    "df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Split data into train and test sets (80-20 split)\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6584443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2 , random_state= 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499ff1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies','Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "numerical = ['tenure', 'MonthlyCharges', 'TotalCharges']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1380a3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\.continuum\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Create transformers for numerical and categorical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "# Create a column transformer that applies the transformers to the appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical ),\n",
    "        ('cat', categorical_transformer, categorical)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final pipeline that includes the column transformer\n",
    "final_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e490aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "X_train_transformed = final_pipeline.fit_transform(X_train)\n",
    "X_test_transformed = final_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92914c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the column names after one-hot encoding\n",
    "categorical_encoder = final_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "one_hot_encoded_cols = categorical_encoder.get_feature_names(input_features=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb614e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the numerical and one-hot encoded column names\n",
    "all_column_names = numerical + list(one_hot_encoded_cols)\n",
    "\n",
    "# Create DataFrames for the transformed data with the correct column names\n",
    "X_train_final = pd.DataFrame(X_train_transformed, columns=all_column_names)\n",
    "X_test_final = pd.DataFrame(X_test_transformed, columns=all_column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5af16ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c95114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train models\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "et_model = ExtraTreesClassifier(random_state=1)\n",
    "et_model.fit(X_train_final, y_train)\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=1)\n",
    "xgb_model.fit(X_train_final, y_train)\n",
    "\n",
    "lgbm_model = LGBMClassifier(random_state=1)\n",
    "lgbm_model.fit(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201035f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9a04b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "rf_pred = rf_model.predict(X_test_final)\n",
    "et_pred = et_model.predict(X_test_final)\n",
    "xgb_pred = xgb_model.predict(X_test_final)\n",
    "lgbm_pred = lgbm_model.predict(X_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cfb4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "et_accuracy = accuracy_score(y_test, et_pred)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "lgbm_accuracy = accuracy_score(y_test, lgbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add13035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.79\n",
      "Extra Trees Accuracy: 0.77\n",
      "XGBoost Accuracy: 0.79\n",
      "LightGBM Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\n",
    "print(f\"Extra Trees Accuracy: {et_accuracy:.2f}\")\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.2f}\")\n",
    "print(f\"LightGBM Accuracy: {lgbm_accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
